<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="by timm, timm@ieee.org" />
  <title>Open Problems in Active Learning for Multi-Objective Optimization</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="ezr.css" />
  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<a href="https://github.com/timm/ezr"> <img
alt="Home" src="https://img.shields.io/badge/home-black"></a> <a href="https://raw.githubusercontent.com/timm/ezr/main/ezr.py"> <img
alt="Download" src="https://img.shields.io/badge/download-gold"></a> <a 
href="https://github.com/timm/ezr/issues"> <img
alt="Issues" src="https://img.shields.io/badge/issues-red"></a> <a 
href="https://github.com/timm/ezr/blob/main/LICENSE.md"> <img
alt="License" src="https://img.shields.io/badge/license-bsd2-green"></a> <img 
src="https://img.shields.io/badge/purpose-ai%20,%20se-blueviolet"> <img
alt="Purpose" src="https://img.shields.io/badge/language-python3-blue">

<p><em>20-40 samples can find significant improvements in 10,000+ examples. Wanna know how?</em><hr>
<header id="title-block-header">
<h1 class="title">Open Problems in Active Learning for Multi-Objective
Optimization</h1>
<p class="author">by timm, <a href="mailto:timm@ieee.org"
class="email">timm@ieee.org</a></p>
<p class="date">© 2024, BSD-2 license</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#the-general-problem" id="toc-the-general-problem"><span
class="toc-section-number">1</span> The general problem:</a></li>
<li><a href="#more-specific-problems"
id="toc-more-specific-problems"><span
class="toc-section-number">2</span> More specific problems:</a>
<ul>
<li><a href="#acquisition-functions"
id="toc-acquisition-functions"><span
class="toc-section-number">2.1</span> Acquisition functions</a></li>
<li><a href="#initial-label-selection"
id="toc-initial-label-selection"><span
class="toc-section-number">2.2</span> Initial label selection</a></li>
<li><a href="#initial-data-selection"
id="toc-initial-data-selection"><span
class="toc-section-number">2.3</span> Initial data selection</a></li>
<li><a href="#clustering" id="toc-clustering"><span
class="toc-section-number">2.4</span> Clustering</a></li>
<li><a href="#streaming" id="toc-streaming"><span
class="toc-section-number">2.5</span> Streaming</a></li>
<li><a href="#oracle-errors" id="toc-oracle-errors"><span
class="toc-section-number">2.6</span> Oracle errors</a></li>
<li><a href="#explanation" id="toc-explanation"><span
class="toc-section-number">2.7</span> Explanation</a></li>
<li><a href="#higher-dimensional-data"
id="toc-higher-dimensional-data"><span
class="toc-section-number">2.8</span> Higher dimensional data</a></li>
<li><a href="#other-data" id="toc-other-data"><span
class="toc-section-number">2.9</span> Other data</a></li>
<li><a href="#benchmark-against-standard-optimizers"
id="toc-benchmark-against-standard-optimizers"><span
class="toc-section-number">2.10</span> Benchmark against standard
optimizers</a></li>
<li><a href="#hyper-parameter-optimization"
id="toc-hyper-parameter-optimization"><span
class="toc-section-number">2.11</span> Hyper-parameter
optimization</a></li>
<li><a href="#non-optimization" id="toc-non-optimization"><span
class="toc-section-number">2.12</span> Non-optimization</a></li>
<li><a href="#llms" id="toc-llms"><span
class="toc-section-number">2.13</span> LLMs</a></li>
</ul></li>
</ul>
</nav>
<hr>
<h2 data-number="1" id="the-general-problem"><span
class="header-section-number">1</span> The general problem:</h2>
<ul>
<li>Given rows of data with many <span class="math inline">\(X\)</span>
independent values and many <span class="math inline">\(Y\)</span> goals
where <span class="math inline">\(Y=f(X)\)</span>:
<ul>
<li>Look at the fewest <span class="math inline">\(Y\)</span>
values</li>
<li>To find what <span class="math inline">\(X\)</span> values predict
for the best <span class="math inline">\(Y\)</span> values</li>
</ul></li>
<li>Curently, we are stuck at at around 30-40 labels (have been for
about a year). Can we get this down to 15-20?</li>
</ul>
<h2 data-number="2" id="more-specific-problems"><span
class="header-section-number">2</span> More specific problems:</h2>
<h3 data-number="2.1" id="acquisition-functions"><span
class="header-section-number">2.1</span> Acquisition functions</h3>
<ul>
<li>Explore? exploit? adaptive?</li>
<li>Uncertainty (or not)</li>
<li>Different for different kinds of data?</li>
<li>Membership query synthesis</li>
</ul>
<h3 data-number="2.2" id="initial-label-selection"><span
class="header-section-number">2.2</span> Initial label selection</h3>
<ul>
<li>Random, diversity, rrp</li>
</ul>
<h3 data-number="2.3" id="initial-data-selection"><span
class="header-section-number">2.3</span> Initial data selection</h3>
<ul>
<li>Full dendogram generation, then reflection across the whole
structure.
<ul>
<li>e.g. sample rows at a frequency equal to leaf diversity</li>
</ul></li>
<li>Divide larger data sets in two (at random)
<ul>
<li>Does a model learnt from first half part work for second part?</li>
<li>How large must the first part be before we can learn a model stable
for the second part?</li>
</ul></li>
</ul>
<h3 data-number="2.4" id="clustering"><span
class="header-section-number">2.4</span> Clustering</h3>
<ul>
<li>Anything better than twoFar?</li>
</ul>
<h3 data-number="2.5" id="streaming"><span
class="header-section-number">2.5</span> Streaming</h3>
<ul>
<li>Early stopping? Track progress to date then stop early</li>
<li>Pool learning:
<ul>
<li>Current tool is a “pool” learner that can access all the unlabelled
examples.</li>
<li>An alternate approach is a “stream” learner that eats the data in
“eras” of size (say) 1000</li>
<li>So instead of starting from zero all the time
<ul>
<li>Restart each era with the model learned from era[-1]</li>
</ul></li>
</ul></li>
<li>Why does the faster heuristic work? can we use that to build a
better algorithm?</li>
</ul>
<h3 data-number="2.6" id="oracle-errors"><span
class="header-section-number">2.6</span> Oracle errors</h3>
<ul>
<li>Assume X% wrong, try things with increasing X
(e.g. 0,10,20,40%)</li>
</ul>
<h3 data-number="2.7" id="explanation"><span
class="header-section-number">2.7</span> Explanation</h3>
<ul>
<li>Can we learn a stable symbolic model that predicts for better?</li>
<li>What is the “explanation tax”; i.e. how much do we lose if we use
the rules?</li>
</ul>
<h3 data-number="2.8" id="higher-dimensional-data"><span
class="header-section-number">2.8</span> Higher dimensional data</h3>
<ul>
<li>Text mining</li>
<li>Audio data</li>
<li>Image data</li>
</ul>
<h3 data-number="2.9" id="other-data"><span
class="header-section-number">2.9</span> Other data</h3>
<ul>
<li>How much of fig7 of
https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2011-8.pdf
can we cover?</li>
<li>some of the goals we are exploring are a little dull. Can we do
better?
<ul>
<li>For https://arxiv.org/pdf/2311.17483.pdf, fig 9, what support can
you add to support (say) 5 of the lefthand side requirements?</li>
<li>This one is challenging. How would you generate the data to explore?
<ul>
<li>But wait! we only need under 40 examples. Does that help us?</li>
</ul></li>
</ul></li>
</ul>
<h3 data-number="2.10" id="benchmark-against-standard-optimizers"><span
class="header-section-number">2.10</span> Benchmark against standard
optimizers</h3>
<ul>
<li>e.g. optuna, hyperplan (BOHB), DE
<ul>
<li>Will need an oracle that can label any example (see “regression” or
“data synthesis”, below)</li>
<li>Or, apply all this to known models
<ul>
<li>e.g <a href="https://github.com/anyoptimization/pymoo">Pymoo</a> has
hundreds of such models</li>
<li>See <a
href="https://pymoo.org/problems/test_problems.html">here</a></li>
<li>The DTLZ models are really widely used (but I fret they are
simplistic):
<ul>
<li>and <a href="https://pymoo.org/problems/dynamic/df.html">DF</a>
looks pretty cool.</li>
</ul></li>
<li>Try to avoid the really simple ones. Try to do something SE
relevant</li>
</ul></li>
</ul></li>
</ul>
<h3 data-number="2.11" id="hyper-parameter-optimization"><span
class="header-section-number">2.11</span> Hyper-parameter
optimization</h3>
<ul>
<li>Can ezr tune ezr?</li>
<li>Can ezr tune other algorithms?</li>
</ul>
<h3 data-number="2.12" id="non-optimization"><span
class="header-section-number">2.12</span> Non-optimization</h3>
<ul>
<li>Classification</li>
<li>Regression</li>
<li>Anomaly detection</li>
<li>Data synthesis
<ul>
<li>Need a measure of new data being the same as old</li>
</ul></li>
<li>Data de-biasing</li>
</ul>
<h3 data-number="2.13" id="llms"><span
class="header-section-number">2.13</span> LLMs</h3>
<ul>
<li>Better than LLM?</li>
<li>Use to select for questions in few shot learning?</li>
<li>Use to select prompts for case based reasoning?</li>
</ul>
</body>
</html>
